% 第三章：多模态数据构造范式
\chapter{多模态数据构造范式}

\section{背景}
当前多模态大语言模型（Multimodal Large Language Model, MLLM）的训练正面临“\textbf{数据质量而非数据数量}”成为主要瓶颈的阶段性转折。一方面，网络抓取的图文对存在噪声大、对齐弱（Misalignment）、图像质量参差不齐（水印、模糊）等问题；另一方面，人工标注成本高且难以覆盖复杂推理与多样化交互格式。已有研究（如ShareGPT4V、MMEvol、SynthVLM）均表明：\textbf{高信息密度、高对齐度与高推理密度的数据}，往往比盲目扩大规模更能有效提升模型能力\citep{chen2023sharegpt4v,xu2024mmevol,liu2025synthvlm}。

为系统性描述并复用高质量数据生产经验，本文提出\textbf{Auto-Evol}多模态合成数据构造范式：将“合成数据生成”从单步的“图$\rightarrow$文/问答”重构为一个包含\textbf{正反双向链路}、\textbf{任务导向的原子问题生成}、\textbf{代理式生成与进化增强}、\textbf{多维校验与闭环反馈}的工程系统。该范式可统一承载不同任务域的数据生产需求：例如第\ref{chap:gui}章面向GUI的Referring/Grounding能力提升与第\ref{chap:world_knowledge}章面向世界知识的RecQA/KnowQA/FinalQA体系，均可视为Auto-Evol在不同任务路由下的具体实例。
更进一步，本章并不将范式作为“抽象概念”孤立呈现，而是以第\ref{chap:gui}章与第\ref{chap:world_knowledge}章的\textbf{数据构造方法}为起点，结合ShareGPT4V、MMEvol、SynthVLM、Synthesize Step-by-Step等工作的可复用组件\citep{chen2023sharegpt4v,xu2024mmevol,liu2025synthvlm,li2024synthesize}，总结得到可落地、可迭代、可验证的多模态数据构造方法学。

% 注：若后续需要对章节号引用更严谨，可在对应章节加label，这里先用文字描述避免未定义引用。

\section{构造范式框架}
图\ref{fig:auto_evol_pipeline}给出了Auto-Evol范式的闭环框架。该框架从数据源侧同时接入\textbf{原生图片}与\textbf{生成图片}两类输入，通过数据初始化统一格式并沉淀生成所需的源信息（可包含自动/人工标注产物），随后进行质量过滤；再将样本路由到“任务导向的原子问题生成”，并按感知、理解、推理三类代理生成多任务指令；最后通过数据增强与数据校验提升多样性、难度与正确性，若校验不过则回流重写/重生成，最终产出可用于监督微调（SFT）与后训练（Post-training）的高质量合成数据。

\begin{figure}[t]
  \centering
  \includegraphics[width=0.70\linewidth]{figures/chapter3/pipeline.pdf}
  \caption{Auto-Evol多模态合成数据闭环Pipeline：数据初始化（含标注）--过滤--原子问题生成--增强与校验--回流重写。}
  \label{fig:auto_evol_pipeline}
\end{figure}

Auto-Evol的构造流程可逐模块映射到图\ref{fig:auto_evol_pipeline}的闭环节点。下文结合第\ref{chap:gui}章（GUI）与第\ref{chap:world_knowledge}章（世界知识）的实践，依次讲解各模块的作用。

\subsection{构造流程}
\paragraph{（1）数据源：原生图片与生成图片的双向数据流}
Pipeline顶部同时接入两类数据源：
\begin{itemize}
  \item \textbf{原生图片（真实收集）}：来自真实应用截图、公开数据集与搜索收集的高清图片。GUI章使用真实设备分辨率截图以保留小控件细节；世界知识章以“词条$\rightarrow$图片”的方式确保实体可控。
  \item \textbf{生成图片（Text-to-Image）}：当长尾场景稀缺或需要严格对齐时，可采用“文本$\rightarrow$图像”的逆向数据工程。SynthVLM表明，先清洗caption再用扩散模型生成高分辨率图像，并用CLIPScore+SSIM筛选，可从源头提高图文对齐度与图像清晰度，从而以更少数据达到更强效果\citep{liu2025synthvlm,hessel2021clipscore,wang2004ssim}。
\end{itemize}
双向数据流的价值在于：\textbf{正向流（图$\rightarrow$文）}擅长覆盖真实分布，\textbf{反向流（文$\rightarrow$图）}擅长制造“强对齐、可控分布”，两者互补可显著提升数据的覆盖与可信度。

\paragraph{（2）数据初始化：统一格式与任务路由的前置条件}
“数据初始化”的核心目标是将不同来源的原始材料整理为后续\textbf{指令/QA生成}阶段可直接\textbf{提取或参考的源信息池}：包括可追溯的元信息（来源、分辨率、类别/词条等）、必要的路由标签，以及与任务相关、可被复用的结构化线索。这里的“源信息”不要求跨数据源完全同构，而是强调\textbf{为生成提供可依赖的参照物}。在实践中，初始化阶段通常会沉淀两类关键产物：
\begin{itemize}
  \item \textbf{自动生成的结构化描述/要素（用于蒸馏的中间表征）}：以世界知识数据为例，初始化阶段往往会先为图片生成结构化caption，并显式区分“画面可见信息”（主体、属性、关系、时空线索等）与“背景知识要点”（年份、导演、题材、所属系列等可核验事实）。该caption随后既可用于图文相关性过滤，也可作为知识要素抽取与RecQA/KnowQA/FinalQA构造时的主要上下文依据，从而把“图像与知识源”转化为可复用、可校验的中间表征。与此同时，为提升大模型蒸馏的可靠性，caption/要素抽取常配套引入：固定输出格式与字段约束（例如先给出实体识别结论，再给出若干可核验事实）、自一致性采样/多次生成投票、以及“生成--判别”式复核（judge过滤不一致或缺乏证据支撑的内容），将不确定与幻觉样本在数据侧前置淘汰。以词条“\emph{1917}（电影）”为例，caption会被要求同时给出图中“士兵/军装/战场环境”等可见证据与“2019、萨姆·门德斯、战争片”等知识要点；随后系统依据caption与词条的一致性保留高相关样本，并据此生成识别锚定的RecQA与需要知识调用/筛选的KnowQA、FinalQA。
  \item \textbf{人工标注与上下文采集（高置信锚点）}：人工标注适用于\textbf{需要像素级精确度}、\textbf{存在强歧义/同名消歧}、或\textbf{需要遵循严格规则与一致性约束}的场景，其作用是为后续生成提供稳定锚点与可复核依据。以GUI任务为例，可沉淀候选控件集合、紧致bbox、OCR文本、控件可交互性/状态（如Activated/Interactable/Filled）以及标签--控件绑定等关系信息，从而支撑Grounding/Referring等任务的可执行监督；以世界知识任务为例，可对词条集合进行边界校正与别名对齐、处理同名实体歧义，并对关键样本进行抽检复核，确保“图片$\leftrightarrow$词条$\leftrightarrow$知识”的对应关系可追溯、可验证。
\end{itemize}

\paragraph{（3）过滤：相关性与准确性的第一道闸门}
“过滤相关性、准确性”是合成数据可用性的核心保障，其目标是尽早剔除“错图错标/弱对齐/不可验证”的样本，避免噪声在后续指令生成与训练中被放大。以第\ref{chap:world_knowledge}章为例，图片来自自动检索，天然会混入同名歧义、相似实体、无关插图等噪声；因此在进入QA构造前，系统会基于“图片$\leftrightarrow$词条”的匹配强度进行\textbf{相关性评分}（1--5分），并要求输出简要理由与固定格式，便于程序解析与自动化处理。在阈值化过滤的同时，为兼顾覆盖率与长尾，流程通常会保留高分样本并对部分中等分样本进行抽样复核，从而在“尽可能保留潜在相关证据”与“抑制错配监督”之间取得平衡。

与之相比，SynthVLM更偏向使用\textbf{自动指标}（如CLIPScore、SSIM等）对图文对齐度与图像质量进行强筛选\citep{liu2025synthvlm,hessel2021clipscore,wang2004ssim}，其优势在于可规模化、可重复；而世界知识任务中的相关性过滤更强调\textbf{语义一致性与可解释性}（尤其是同名消歧与实体锚定）。两者共同指向同一结论：过滤不仅是去噪，更是\textbf{控制训练信号可信度与信息密度}的关键环节。

\paragraph{（4）任务导向的原子问题生成（三基础能力/三生成链路）}
在Auto-Evol中，“\textbf{把任意多模态任务统一分解为感知、理解、推理三类基础能力，并为每一类能力设计对应的数据生成链路与监督信号}。因此，三代理生成不仅是工程上的分工，更是多模态模型能力结构的抽象——其他任务数据（如GUI定位与交互、世界知识识别与问答、多轮对话、工具调用等）都可以视为三类能力的组合与不同权重的路由结果。

具体而言，Pipeline中的三条生成链路可概括为：
\begin{itemize}
  \item \textbf{感知链路（Perception）}：以图像为主要证据，生成可\textbf{直接对齐到视觉区域/实体}的监督信号（如bbox、OCR文本、实体识别锚定）。例如在GUI中，感知链路产出紧致bbox与文本对齐，使模型学会在密集小控件场景下稳定“指哪打哪”；在世界知识中，感知链路对应RecQA：先把图片中的具体实例可靠地锚定到词条实体，解决“看见但叫不出名字/叫错名字”的问题。
  \item \textbf{理解链路（Understanding）}：在感知锚点基础上，生成\textbf{高密度语义解释}与可复用上下文（如结构化caption、关系解释、背景知识片段），提升语义覆盖与可解释性。以世界知识为例，初始化阶段沉淀的结构化caption把“画面可见信息”与“背景知识要点”组织成稳定上下文，理解链路据此构造KnowQA，将可泛化的事实知识与实体绑定；以GUI为例，理解链路对应Referring类数据：给定bbox输出控件功能/文本/属性及其与周边元素的关系，从而让模型学会“看懂”而不仅是“定位”。
  \item \textbf{推理链路（Reasoning）}：在“感知锚定 + 语义/知识上下文”之上，生成需要\textbf{多步条件推断}的监督信号，并尽可能加入过程性约束以避免短路学习。以世界知识为例，FinalQA要求模型先识别实体再调用知识完成筛选/推断，并在加入Think/CoT后显著提升推理指标，说明推理链路必须提供“先识别再推理”的过程监督；以GUI为例，推理链路对应包含多步计划与工具调用约束的任务数据，使模型学习在页面状态、控件关系与目标约束下生成可执行的动作序列。
\end{itemize}
通过上述三链路路由，Auto-Evol把“难任务”拆成“可控生成、可控校验”的组合单元：感知链路提供可对齐的锚点，理解链路提供可复用的语义/知识上下文，推理链路提供过程性约束与可验证推断，从而系统性降低错配与幻觉传播，并提升数据的可迁移性与覆盖度。

\paragraph{（5）数据增强：细粒度、难度、指令多样性的系统注入}
Pipeline中的“数据增强”可理解为对训练信号的三条系统性“加密”方向，它们既对应数据侧要解决的三类瓶颈，也对应模型希望被强化能力，即关注细节、攻克难题、与人交互的能力：
\begin{itemize}
  \item \textbf{细粒度增强（对齐粒度 $\rightarrow$ 感知能力）}：针对多模态数据常见的“对齐粒度不够/忽略长尾细节”问题，围绕图像中的次要物体、背景细节与空间关系补充监督，使模型学习到更细的视觉证据与文本描述之间的对应关系。MMEvol的\emph{Fine-grained Perception Evolution}提供了一个可操作范式\citep{xu2024mmevol}：利用检测框等视觉约束，将问题生成从“主目标描述”扩展到“被忽略区域/长尾物体”的定向提问，从而减少“看见但不说/说错”的幻觉风险。对应到本文任务中，GUI场景的小控件与小字体天然属于细粒度信息，补充紧致bbox与OCR对齐监督，本质上就是对感知链路的信息密度加密。
  \item \textbf{难度增强（推理密度 $\rightarrow$ 推理能力）}：针对“指令复杂性不足/缺乏深度推理步骤”的问题，通过多步推理、条件约束与可执行步骤显式提升推理密度。例如可以将推理抽象为“视觉操作链”（如定位、OCR、存在性判断、计数/计算等原子操作），并要求在输出答案前生成可追踪的推理步骤，从而把“难题”转化为可校验的过程监督。本文在世界知识任务中对FinalQA加入Think/CoT（要求先识别实体，再调用知识完成筛选/推断），并在实验中观察到推理指标显著提升，正体现了“过程性推理监督”对推理能力增强的关键作用。
  \item \textbf{指令多样性增强（交互覆盖 $\rightarrow$ 理解与指令遵循能力）}：针对“指令形式单一/交互覆盖不足”的问题，将同一语义目标改写为多样化的交互形式（如结构化JSON、代码片段、角色设定、多轮对话等），以提升模型对不同用户表达与输出约束的鲁棒性。MMEvol的\emph{Interaction Evolution}强调在保持视觉约束的前提下扩展输出格式与交互方式\citep{xu2024mmevol}，避免仅做“文本复杂化”而脱离图像证据；在Auto-Evol中，该方向对应理解链路的格式多样化注入，使模型既学会“说对”，也学会“按要求说”。
\end{itemize}

\paragraph{（6）数据校验：LLM-as-a-Judge + 工具/执行校验的多维验证}
高质量合成数据必须“可验证”。更准确地说，\textbf{数据校验就是对数据做评测}：围绕“我们希望模型最终具备什么能力”，反向定义数据应满足的作用与特性，并在生成后用可操作的评测准则筛选与修正数据分布。总之想要什么样的数据，就要用对应方法校验才能得到，例如这三类比较普遍的校验：
\begin{itemize}
  \item \textbf{难度校验（过滤“过于简单”的样本）}：若目标是让模型解决难题，则需要避免训练集中被大量“简单题”稀释。实践中可用\textbf{能力较弱的模型}或规则基线先行作答：若弱模型在不依赖关键视觉/知识证据的情况下即可轻易答对，则该样本更可能属于低难度或存在捷径，可降权、剔除或重写以提升推理密度。
  \item \textbf{正确性与可验证性校验（确保监督信号“对”）}：若目标是让模型切实学会某项能力，则监督必须可靠。可用\textbf{更强的模型}进行一致性复核（例如答案唯一性、推理链条自洽、与图像证据相符），并对推理类样本引入\textbf{工具/执行校验}（如代码执行、规则验证、可解析约束检查）来验证最终答案与中间步骤的一致性，从源头抑制错误监督与幻觉传播。
  \item \textbf{覆盖与多样性校验（保证可泛化的交互学习）}：若目标是提升交互与指令遵循鲁棒性，则数据需要在任务类型、表达方式与输出格式上足够多样。可通过分布统计与约束检查（任务路由占比、模板去重、格式合法性、长尾覆盖等）评估并调整数据，使模型既学会“答对”，也学会“按要求答”。
\end{itemize}

\paragraph{（7）回流重写/重生成：闭环提升与分布自适应}
当某类任务通过率持续偏低时，系统触发右侧“重写”回路：要么对指令/答案进行重写（保持图像不变），要么回流到“生成图片”分支重新合成更契合任务的图像，再进入流程。该闭环使数据系统具备“自我修复”的能力，避免一次性生成导致的质量不可控的同时也不要浪费以得倒的信息。

\subsection{从两类任务实践到统一范式的归纳}
需要强调的是，Auto-Evol并非“从概念出发”的抽象框图，也不只是对两章工作的事后总结，而是建立在\textbf{系统性相关工作调研}与\textbf{本文多模态数据/训练实践}之上的方法学抽象：一方面，ShareGPT4V、SynthVLM、MMEvol、Synthesize Step-by-Step等工作分别从高密度对齐、逆向数据工程、进化式增强与过程可执行推理等角度提供了可复用的模块化思想\citep{chen2023sharegpt4v,liu2025synthvlm,xu2024mmevol,li2024synthesize}；另一方面，本文在多模态任务落地过程中形成了关于多源数据组织、结构化标注、过程性监督与质量控制的一系列工程经验。下面以GUI与世界知识两条主线作为代表性实例说明该范式的归纳来源：
\begin{itemize}
  \item \textbf{GUI主线（第\ref{chap:gui}章）}：以\textbf{结构化初始化}与\textbf{细粒度标注}为核心，将“截图”转化为可计算的控件集合（bbox、OCR、状态向量、关系图谱），再围绕Referring/Grounding生成任务化监督，并通过多源融合与质控迭代提升稳定性。该主线强调“\textbf{可执行定位}”与“\textbf{可解释语义}”的双对齐，并体现了细粒度对齐与分层能力路由在复杂交互场景中的必要性。
  \item \textbf{世界知识主线（第\ref{chap:world_knowledge}章）}：以\textbf{实体锚定}与\textbf{知识注入}为核心，通过“词条$\rightarrow$图片$\rightarrow$caption$\rightarrow$相关性过滤$\rightarrow$RecQA/KnowQA/FinalQA”建立从知识源到可学习多模态监督的转化链路，并通过\textbf{带推理过程（Think/CoT）的FinalQA}强化“先识别再推理”的可迁移推理策略。该主线强调“\textbf{可验证对齐}”与“\textbf{推理链路贯通}”，对应了过程监督与可校验链路对世界知识推理能力提升的关键作用。
  \item \textbf{跨任务复用的工程实践（本文其他多模态工作）}：除上述两类任务外，本文在多模态数据构造与训练中还沉淀了可跨任务复用的通用做法，例如：以统一的“源信息池”承接不同数据源与标注形态、以三基础能力链路统一组织监督信号、以及以“难度/正确性/覆盖多样性”为目标对数据进行评测式校验。这些实践与调研结论共同促成了Auto-Evol作为统一范式的可迁移性与可扩展性。
\end{itemize}
二者看似任务不同，但其共同结构恰好对应Auto-Evol的闭环：\textbf{统一表示}承接多源输入，\textbf{原子化任务拆解}把复杂能力拆成可监督信号，\textbf{分层代理生成}提升信息密度与多样性，\textbf{多维过滤/校验与回流}控制噪声与幻觉并推动持续迭代。因此，Auto-Evol可被视为“面向不同任务路由的数据生产系统”，既能覆盖GUI这类强几何/强交互任务，也能覆盖世界知识这类强对齐/强推理任务。

\section{模块有效性验证}
Auto-Evol的关键模块并非凭经验堆叠，其必要性可在第4章与第5章的实验结果中得到直接验证。下面从“模块$\rightarrow$证据”的角度进行归因式总结。

\paragraph{（A）多源融合与结构化监督的必要性（对应初始化（含标注）/过滤）}
在GUI任务中，仅靠基线模型性能较低；引入开源清洗数据后指标显著提升，而进一步融合闭源精标数据后提升更为明显：如表\ref{tab:gui_data_ablation}所示，Grounding F1由0.324提升至0.846，Referring F1由0.523提升至0.905。该结果表明，\textbf{多源覆盖 + 结构化标注 + 质量控制}能够显著提高定位与理解的稳定性，是Auto-Evol“数据初始化--协作标注--过滤”的直接实证。

\paragraph{（B）中间表征与相关性过滤的必要性（对应caption与对齐校验）}
在世界知识任务中，caption不仅提供“更丰富的描述”，更作为可依赖的中间表征支撑相关性过滤与后续QA构造。实验一的结论指出：\textbf{Image Caption对识别显著有益}（表\ref{tab:wk_ablation_part1}），说明“中间表征 + 对齐筛选”能够为实体锚定提供更稳健的训练信号，对应Auto-Evol中“过滤相关性、准确性”与“相关性校验”的设计动机。

\paragraph{（C）显式推理过程数据对推理能力的显著增益（对应原子化/推理代理/执行校验）}
第\ref{chap:world_knowledge}章进一步揭示：仅监督最终答案的FinalQA可能诱发“短路映射”，导致推理指标提升不显著甚至下降；而当FinalQA加入简要推理过程（Think/CoT）并扩充数据分布后，final相关指标\textbf{出现显著提升}。如表\ref{tab:wk_think_improve}所示，在Chinese SimpleVQA上，\texttt{Ovis2.5\_9B\_think\_part123}相对\texttt{qwen2.5-VL-7b}在F1\_Final上提升11.9个点（同时F1\_Rec提升16.1个点），验证了“\textbf{显式推理链路监督}”对可迁移推理能力的关键作用。这一现象与Auto-Evol强调的“原子化任务拆解 + 推理代理生成 + 多维校验（含可执行/一致性校验）”相一致：通过过程性监督与可验证机制，才能在提升推理强度的同时抑制幻觉与短路学习。

\section{本章小结}
本章围绕“数据质量成为瓶颈”的现实约束，提出并系统化阐释了\textbf{Auto-Evol}多模态数据构造范式。其核心意义在于：将以往零散、一次性的合成数据生成，升级为一个\textbf{可路由、可评测、可闭环迭代}的数据生产系统，从而稳定地产出高信息密度、高对齐度与高推理密度的训练信号。

具体贡献体现在三点：\textbf{（1）统一能力视角}——以感知/理解/推理三基础能力为坐标系，把不同任务的数据需求统一到三条生成链路与可复用监督信号上，避免“为每个任务重新设计一套数据体系”；\textbf{（2）评测式质控}——将数据校验显式定义为对数据的评测，围绕难度、正确性/可验证性与覆盖多样性进行筛选与分布修正，降低错配监督与幻觉传播风险；\textbf{（3）闭环可持续迭代}——通过过滤、增强、校验与回流重写把失败样本转化为下一轮优化目标，使数据分布能够随任务瓶颈自适应演化。

范式的有效性在后续章节得到量化支撑：在GUI任务中，多源融合与结构化监督显著提升Grounding/Referring性能（表\ref{tab:gui_data_ablation}）；在世界知识任务中，引入中间表征与过程性推理监督（Think/CoT）带来推理指标的显著增益（表\ref{tab:wk_think_improve}）。因此，Auto-Evol既为第\ref{chap:gui}章与第\ref{chap:world_knowledge}章提供统一的数据工程底座，也为后续扩展到更多多模态场景提供了可复用的方法学框架。

