@inproceedings{liu2025synthvlm,
  title={SynthVLM: Towards High-Quality and Efficient Synthesis of Image-Caption Datasets for Vision-Language Models},
  author={Liu, Zheng and Liang, Hao and Li, Bozhou and Xiong, Wentao and Chen, Chong and He, Conghui and Zhang, Wentao and Cui, Bin},
  booktitle={Proceedings of the 33rd ACM International Conference on Multimedia},
  year={2025},
  publisher={ACM},
  doi={10.1145/3746027.3758222}
}

@article{chen2023sharegpt4v,
  title={ShareGPT4V: Improving Large Multi-Modal Models with Better Captions},
  author={Chen, Lin and Li, Jinsong and Dong, Xiaoyi and Zhang, Pan and He, Conghui and Wang, Jiaqi and Zhao, Feng and Lin, Dahua},
  journal={arXiv preprint arXiv:2311.12793},
  year={2023},
  url={https://arxiv.org/abs/2311.12793}
}

@article{mitra2024agentinstruct,
  title={AgentInstruct: Toward Generative Teaching with Agentic Flows},
  author={Mitra, Arindam and Del Corro, Luciano and Zheng, Guoqing and Mahajan, Shweti and Rouhana, Dany and Codas, Andres and Lu, Yadong and Chen, Wei-ge and Vrousgos, Olga and Rosset, Corby and others},
  journal={arXiv preprint arXiv:2407.03502},
  year={2024},
  url={https://arxiv.org/abs/2407.03502}
}

@inproceedings{wang2023selfinstruct,
  title={Self-Instruct: Aligning Language Models with Self-Generated Instructions},
  author={Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A. and Khashabi, Daniel and Hajishirzi, Hannaneh},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={13484--13508},
  year={2023},
  url={https://aclanthology.org/2023.acl-long.754}
}

@article{li2024synthesize,
  title={Synthesize Step-by-Step: Tools, Templates and LLMs as Data Generators for Reasoning-Based Chart VQA},
  author={Li, Zhuowan and Jasani, Bhavan and Tang, Peng and Ghadar, Shabnam},
  journal={arXiv preprint arXiv:2403.16385},
  year={2024},
  url={https://arxiv.org/abs/2403.16385}
}

@inproceedings{liu2024visual,
  title={Visual Instruction Tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  booktitle={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024},
  note={LLaVA Model}
}

@inproceedings{liu2023improved,
  title={Improved Baselines with Visual Instruction Tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  pages={26296--26306},
  year={2024},
  note={LLaVA-1.5}
}

@inproceedings{radford2021learning,
  title={Learning Transferable Visual Models From Natural Language Supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR},
  note={CLIP}
}

@inproceedings{li2023blip2,
  title={BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International Conference on Machine Learning},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}

@article{bai2023qwenvl,
  title={Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  year={2023}
}

@article{podell2023sdxl,
  title={SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis},
  author={Podell, Dustin and English, Zion and Lacey, Kyle and Blattmann, Andreas and Dockhorn, Tim and M{\"u}ller, Jonas and Penna, Joe and Rombach, Robin},
  journal={arXiv preprint arXiv:2307.01952},
  year={2023}
}

@inproceedings{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  booktitle={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022},
  note={InstructGPT}
}

@inproceedings{wei2022chain,
  title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Chi, Ed and Le, Quoc and Zhou, Denny},
  booktitle={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{mukherjee2023orca,
  title={Orca: Progressive Learning from Complex Explanation Traces of GPT-4},
  author={Mukherjee, Subhabrata and Mitra, Arindam and Jawahar, Ganesh and Agarwal, Sahaj and Palangi, Hamid and Awadallah, Ahmed},
  journal={arXiv preprint arXiv:2306.02707},
  year={2023}
}

@inproceedings{wang2022super,
  title={Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ Tasks},
  author={Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Arunkumar, Anjana and Ashok, Arjun and Dhanasekaran, Arut Selvan and Naik, Atharva and Stap, David and others},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={5085--5109},
  year={2022}
}

@inproceedings{liu2022matcha,
  title={MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering},
  author={Liu, Fangyu and Piccinno, Francesco and Krichene, Syrine and Pang, Chenxi and Lee, Kenton and Joshi, Mandar and Altun, Yasemin and Eisenschlos, Julian Martin},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={12756--12770},
  year={2023}
}

@inproceedings{liu2022deplot,
  title={DePlot: One-shot visual language reasoning by plot-to-table translation},
  author={Liu, Fangyu and Eisenschlos, Julian Martin and Piccinno, Francesco and Krichene, Syrine and Pang, Chenxi and Lee, Kenton and Joshi, Mandar and Chen, Wenhu and Collier, Nigel and Altun, Yasemin},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  pages={10724--10732},
  year={2023}
}

@inproceedings{lee2023pix2struct,
  title={Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding},
  author={Lee, Kenton and Joshi, Mandar and Turc, Iulia and Hu, Hexiang and Liu, Fangyu and Eisenschlos, Julian and Khandelwal, Urvashi and Shaw, Peter and Chang, Ming-Wei and Toutanova, Kristina},
  booktitle={International Conference on Machine Learning},
  pages={18893--18912},
  year={2023},
  organization={PMLR}
}

@inproceedings{masry2022chartqa,
  title={ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning},
  author={Masry, Ahmed and Long, Do Xuan and Tan, Jia Qing and Joty, Shafiq and Hoque, Enamul},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2022},
  pages={2263--2279},
  year={2022}
}

@article{wei2024simpleqa,
  title={SimpleQA: Measuring Short-form Factuality in Large Language Models},
  author={Wei, Jason and Wainakh, Yana and Tu, Romina and Thoppilan, Romal and Shorten, Taylor and Qian, Da and Palladino, Wade and Nayak, Nihal and Laurel, Julian and Ealkon, Sarah and others},
  journal={arXiv preprint arXiv:2411.04368},
  year={2024},
  url={https://arxiv.org/abs/2411.04368}
}

@article{xu2024mmevol,
  title={MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct},
  author={Xu, Runya and Wei, Jun and Lin, Xinyu and Yu, Yisheng and Wu, Yingwei and Sun, Yan and Zhang, Wei and Chang, Jiaqi and Zhang, Xiaotan and Li, Peng},
  journal={arXiv preprint arXiv:2409.05840},
  year={2024},
  url={https://arxiv.org/abs/2409.05840}
}

@inproceedings{alayrac2022flamingo,
  title={Flamingo: a Visual Language Model for Few-Shot Learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={35},
  pages={23716--23736},
  year={2022},
  url={https://proceedings.neurips.cc/paper_files/paper/2022/hash/960a172bc7fbf0177ccccbb411a7d438-Abstract-Conference.html}
}

@inproceedings{deka2017rico,
  title={Rico: A Mobile App Dataset for Building Data-Driven Design Applications},
  author={Deka, Biplab and Huang, Zifeng and Franzen, Chad and Hibschman, Joshua and Afergan, Daniel and Li, Yang and Nichols, Jeffrey and Kumar, Ranjitha},
  booktitle={Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology (UIST)},
  year={2017},
  doi={10.1145/3126594.3126651}
}

@inproceedings{li2022clay,
  title={Learning to Denoise Raw Mobile UI Layouts for Improving Datasets at Scale},
  author={Li, Gang and Baechler, Gilles and Tragut, Manuel and Li, Yang},
  booktitle={Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (CHI)},
  year={2022},
  doi={10.1145/3491102.3502042},
  url={https://doi.org/10.1145/3491102.3502042}
}

@article{gao2024mobileviews,
  title={MobileViews: A Million-scale and Diverse Mobile GUI Dataset},
  author={Gao, Longxi and Zhang, Li and Wang, Shihe and Gao, Pengzhi and Liu, Wei and Luan, Jian and Wang, Shangguang and Li, Yuanchun and Xu, Mengwei},
  journal={arXiv preprint arXiv:2409.14337},
  year={2024},
  url={https://arxiv.org/abs/2409.14337}
}

@article{wu2024osatlas,
  title={OS-ATLAS: A Foundation Action Model for Generalist GUI Agents},
  author={Wu, Zhiyong and Wu, Zhenyu and Xu, Fangzhi and Wang, Yian and Sun, Qiushi and Jia, Chengyou and Cheng, Kanzhi and Ding, Zichen and Chen, Liheng and Liang, Paul Pu and Qiao, Yu},
  journal={arXiv preprint arXiv:2410.23218},
  year={2024},
  url={https://arxiv.org/abs/2410.23218}
}

@misc{droidbot,
  title={DroidBot: A lightweight UI-guided test input generator for Android},
  author={{Honeynet Project}},
  howpublished={\url{https://honeynet.github.io/droidbot/}},
  note={Accessed 2026-01-29}
}

@InProceedings{redmon2016yolo,
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  title={You Only Look Once: Unified, Real-Time Object Detection},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={779--788},
  url={https://arxiv.org/abs/1506.02640}
}

@article{du2020ppocr,
  title={PP-OCR: A Practical Ultra Lightweight OCR System},
  author={Du, Yuning and Li, Chenxia and Guo, Ruoyu and Yin, Xiaoting and Liu, Weiwei and Zhou, Jun and Bai, Yifan and Yu, Zilin and Yang, Yehua and Dang, Qingqing and Wang, Haoshuang},
  journal={arXiv preprint arXiv:2009.09941},
  year={2020},
  url={https://arxiv.org/abs/2009.09941}
}

@article{wang2004ssim,
  author={Wang, Zhou and Bovik, Alan C. and Sheikh, Hamid R. and Simoncelli, Eero P.},
  title={Image Quality Assessment: From Error Visibility to Structural Similarity},
  journal={IEEE Transactions on Image Processing},
  year={2004},
  volume={13},
  number={4},
  pages={600--612},
  doi={10.1109/TIP.2003.819861}
}

@inproceedings{hessel2021clipscore,
  title={CLIPScore: A Reference-free Evaluation Metric for Image Captioning},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Le Bras, Ronan and Choi, Yejin},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  year={2021},
  pages={7514--7528},
  doi={10.18653/v1/2021.emnlp-main.595},
  url={https://aclanthology.org/2021.emnlp-main.595/}
}

@article{bai2025qwen25vl,
  title={Qwen2.5-VL Technical Report},
  author={Bai, Shuai and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Song, Sibo and Dang, Kai and Wang, Peng and Wang, Shijie and Tang, Jun and Zhong, Humen and others},
  journal={arXiv preprint arXiv:2502.13923},
  year={2025},
  url={https://arxiv.org/abs/2502.13923}
}

@article{openai2024gpt4o,
  title={GPT-4o System Card},
  author={OpenAI},
  journal={arXiv preprint arXiv:2410.21276},
  year={2024},
  url={https://arxiv.org/abs/2410.21276}
}


